{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Programming: Simplex Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karush-Kuhn-Tucker Conditions\n",
    "\n",
    "We consider the linear program\n",
    "\n",
    "\\begin{equation}\n",
    "\\min \\vec{c}^\\mathsf{T}\\vec x\\\\\n",
    "\\textrm{subject to} \\begin{cases}\n",
    "\\mathbf{A}\\vec x=\\vec b\\\\\n",
    "\\vec x\\ge\\vec 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "and define the Lagrangian function\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal L\\left(\\vec x,\\vec \\lambda\\right) = \\vec{c}^\\mathsf{T}\\vec x - \\vec \\lambda^\\mathsf{T}\\left(\\mathbf A\\vec x-\\vec b\\right) - \\vec s^\\mathsf{T}\\vec x\n",
    "\\end{equation}\n",
    "\n",
    "where $\\vec \\lambda$ are the multipliers for the equality constraints and $\\vec s$ are the multipliers for the bound constraints.\n",
    "\n",
    "The Karush-Kuhn-Tucker condition states that to find the first-order necessary conditions for $\\vec x^\\star$ to be a solution of the problem, their exist $\\vec \\lambda^\\star$ and $\\vec s^\\star$ such that\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf A^\\mathsf{T}\\vec \\lambda^\\star+\\vec s^\\star&=\\vec c\\\\\n",
    "\\mathbf A\\vec x^\\star&=\\vec b\\\\\n",
    "\\vec x^\\star&\\ge\\vec 0\\\\\n",
    "\\vec s^\\star&\\ge \\vec 0\\\\\n",
    "\\left(\\vec x^\\star\\right)^\\mathsf{T}\\vec s^\\star&=0\n",
    "\\end{align}\n",
    "\n",
    "The first eqation states that the gradient of the Lagrangian with respect to $\\vec x$ must be zero and the last equation that at least $x_i$ or $s_i$ must be zero for each $i=1,2,\\dots,n$.\n",
    "\n",
    "It can be shown that these conditions are also sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Simplex Method Explained\n",
    "\n",
    "As mentioned in the previous lecture, all iterates of the simplex method are basic feasible points and therefore vertices of the feasible polytope. Most steps consists of a move from one vertex to an adjacent one. On most steps (but not all), the value of the objective function $\\vec{c}^\\mathsf{T}\\vec x$ is decreased. Another type of step occurs when the problem is unbounded: the step is an edge along which the objective funtion is reduced, andalong which we can move infinitely far without reaching a vertex.\n",
    "\n",
    "The major issue at each simplex iteration is to decide which index to remove from the basic index set $\\mathcal B$. Unless the step is a direction of unboundness, a single index must be removed from $\\mathcal B$ and replaced by another from outside $\\mathcal B$. We can gain some insight into how this decision is made by looking again at the KKT conditions.\n",
    "\n",
    "First, define the nonbasic index set $\\mathcal N = \\left\\{1,2,\\dots,n\\right\\} \\setminus \\mathcal B$. Just as $\\mathsf B$ is the basic matrix, whose columns are $\\mathsf A_i$ for $i\\in\\mathcal B$, we use $N$ to denote the nonbasic matrix $N=\\left[\\mathbf A_i\\right]_{i\\in\\mathcal N}$. We also partition the vectors $\\vec x$, $\\vec s$ and $\\vec c$ according to the index sets $\\mathcal B$  and $\\mathcal N$, using the notation\n",
    "\n",
    "\\begin{align}\n",
    "\\vec x_\\mathbf B=\\left[\\vec x_i \\right]_{i\\in\\mathcal B},&\\qquad\\vec x_\\mathbf N=\\left[\\vec x_i \\right]_{i\\in\\mathcal N}\\\\\n",
    "\\vec s_\\mathbf B=\\left[\\vec s_i \\right]_{i\\in\\mathcal B},&\\qquad\\vec s_\\mathbf N=\\left[\\vec s_i \\right]_{i\\in\\mathcal N}\\\\\n",
    "\\vec c_\\mathbf B=\\left[\\vec c_i \\right]_{i\\in\\mathcal B},&\\qquad\\vec c_\\mathbf N=\\left[\\vec c_i \\right]_{i\\in\\mathcal N}\n",
    "\\end{align}\n",
    "\n",
    "From the second KKT coniditions, we have that\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf A \\vec x= \\mathbf B \\vec x_\\mathbf B + \\mathbf N \\vec x_\\mathbf N=\\vec b\\,.\n",
    "\\end{equation}\n",
    "\n",
    "The _primal_ variable $\\vec x$ for this simplex iterate is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec x_\\mathbf B = \\mathbf B^{-1}\\vec b,\\qquad \\vec x_\\mathbf N=\\vec 0\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Since we are dealing only with basic feasible points, we know that $\\mathbf B$ is nonsingular and that $\\vec x_\\mathbf B\\ge\\vec0$, so this choice of $\\vec x$ satisfies two of the KKT coniditions.\n",
    "\n",
    "We choose $\\vec s$ to satisfy the complimentary condition (the last one) by setting $\\vec s_\\mathbf B=\\vec 0$. The remaining components $\\vec \\lambda$ and $\\vec s_\\mathbf N$ can be found by partitioning this condition into $\\vec c_\\mathbf B$ and $\\vec c_\\mathbf N$ components and using $\\vec s_\\mathbf B=\\vec 0$ to obtain\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf B^\\mathsf{T}\\vec \\lambda=\\vec c_\\mathbf B,\\qquad \\vec N^\\mathsf{T}\\vec\\lambda+\\vec s_\\mathbf N = \\vec c_\\mathbf N\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Since $\\mathbf B$ is square and nonsingular, the first equation uniquely defines $\\vec \\lambda$ as\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec \\lambda = \\left(\\mathbf B^\\mathsf{T}\\right)^{-1}\\vec c_\\mathbf B\\,.\n",
    "\\end{equation}\n",
    "\n",
    "The second equation implies a value for $\\vec s_\\mathbf N$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec s_\\mathbf N = \\vec c_\\mathbf N - \\mathbf N^\\mathsf{T}\\vec \\lambda=\\vec c_\\mathbf N -\\left(\\mathbf B ^{-1}\\mathbf N\\right)^\\mathsf{T}\\vec c_\\mathbf B\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Computation of the vector $\\vec s_\\mathbf N$ is often referred to as _pricing_. The components of $\\vec s_\\mathbf N$ are often called the _reduced costs_ of the nonbasic variables $\\vec x_\\mathbf N$.\n",
    "\n",
    "The only KKT condition that we have not enforced explicitly is the nonnegativity condition $\\vec s \\ge \\vec 0$. The basic components $\\vec s_\\mathbf B$ certainly satisfy this condition, by our choice $\\vec s_\\mathbf B = 0$. If the vector $\\vec s_\\mathbf N$ also satisfies $\\vec s_\\mathbf N \\ge \\vec 0$, we have found an optimal\n",
    "vector triple $\\left(\\vec x^\\star, \\vec \\lambda^\\star, \\vec s^\\star\\right)$, so the algorithm can terminate and declare success. Usually, however, one or more of the components of $\\vec s_\\mathbf N$ are negative. The new index to enter the basis index set $\\mathcal B$ is chosen to be one of the indices $q \\in \\mathcal N$ for which $s_q < 0$. As we show below, the objective $\\vec{c}^\\mathsf{T}\\vec x$ will decrease when we allow $x_q$ to become positive if and only if \n",
    "\n",
    "1. $s_q < 0$ and\n",
    "2. it is possible to increase $x_q$ away from zero while maintaining feasibility of $\\vec x$.\n",
    "\n",
    "Our procedure for altering $\\mathcal B$ and changing $\\vec x$ and $\\vec s$ can be described accordingly as follows:\n",
    "\n",
    "- allow $x_q$ to increase from zero during the next step;\n",
    "- fix all other components of $\\vec x_\\mathbf N$ at zero, and figure out the effect of increasing $x_q$ on the current basic vector $\\vec x_\\mathbf B$, given that we want to stay feasible with respect to the equality constraints $\\mathbf{A}\\vec x=\\vec b$;\n",
    "- keep increasing $x_q$ until one of the components of $\\vec x_\\mathbf B$ ($x_p$, say) is driven to zero, or determining that no such component exists (the unbounded case);\n",
    "- remove index $p$ (known as the leaving index) from $\\mathcal B$ and replace it with the entering index $q$.\n",
    "\n",
    "This process of selecting entering and leaving indices, and performing the algebraic operations necessary to keep track of the values of the variables $\\vec x$, $\\vec \\lambda$, and $\\vec s$, is sometimes known as _pivoting_.\n",
    "\n",
    "We now formalize the pivoting procedure in algebraic terms. Since both the new iterate $\\vec x^+$ and the current iterate $\\vec x$ should satisfy $\\mathbf A\\vec x=\\vec b$, and since $\\vec x_\\mathbf N=\\vec 0$ and $\\vec x_i^{+}=0$ for $i\\in\\mathcal N\\setminus\\left\\{q\\right\\}$ we have\n",
    "\n",
    "\\begin{equation}\n",
    "A\\vec x^+=B\\vec x_\\mathbf B^+\\mathbf A_q\\vec x_q^+=\\vec b=\\mathbf B\\vec x_\\mathbf B=\\mathbf A\\vec x\\,.\n",
    "\\end{equation}\n",
    "\n",
    "By multiplying this expression by $\\mathbf B^{-1}$ and rearranging, we obtain\n",
    "\n",
    "\\begin{equation}\n",
    "x_\\mathbf B^+=x_\\mathbf B-\\mathbf B^{-1}\\vec A_q\\vec x_q^+\n",
    "\\end{equation}\n",
    "\n",
    "Geometrically speaking, we move along an edge of the feasible polytope that decreases $\\vec{c}^\\mathsf{T}\\vec x$. We continue to move along this edge until a new vertex is encountered. At this vertex, a new constraint $x_p \\ge 0$ must have become active, that is, one of the components $x_p$, $p \\in \\mathbf B$, has decreased to zero. We then remove this index $p$ from the basis index set $\\mathcal B$ and replace it by $q$.\n",
    "\n",
    "It is possible that we can increase $x_q^+$ to $\\infty$ without ever encountering a new vertex. In other words, the constraint $x_\\mathbf B^+=x_\\mathbf B-\\mathbf B^{-1}\\vec A_q\\vec x_q^+\\ge 0$ holds for all positive values of $x_q+$. When this happens, the linear program is unbounded; the simplex method has identified a\n",
    "ray that lies entirely within the feasible polytope along which the objective $\\vec{c}^\\mathsf{T}\\vec x$ decreases to $−\\infty$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Step of Simplex Algorithm\n",
    "\n",
    "Given $\\mathcal B$, $\\mathcal N$, $x_\\mathbf B=\\mathbf B^{-1}\\vec b\\ge 0$,$\\vec x_\\mathbf N=\\vec 0$;\n",
    "\n",
    "1. Solve $\\vec \\lambda = \\left(\\mathbf B^\\mathsf{T}\\right)^{-1}\\vec c_\\mathbf B$, and  compute $\\vec s_\\mathbf N =\\vec c_\\mathbf N - \\mathbf N^\\mathsf{T} \\vec \\lambda$ (pricing);\n",
    "2. If $\\vec s_\\mathbf N \\ge \\vec 0$ stop (optimal point found);\n",
    "3. Select $q\\in\\mathcal N$ with $s_q<0$ and solve $\\vec d=\\mathbf B^{-1}\\vec A_q$;\n",
    "4. If $\\vec d\\le\\vec 0$ stop (problem is unbounded);\n",
    "5. Calculate $x_q^+=\\min_{i|d_i>0}\\frac{\\left(x_\\mathbf B\\right)_i}{d_i}$, and use $p$ to denote the minimizing $i$;\n",
    "6. Update $\\vec x_\\mathbf B^+=\\vec x_\\mathbf B-x_q^+\\vec d$;\n",
    "7. Change $\\mathcal B$ by adding $q$ and removing the basic variable corresponding to column $p$ of $\\mathbf B$.\n",
    "\n",
    "We illustrate this procedure with a simple example.\n",
    "\n",
    "Consider the problem\n",
    "\n",
    "\\begin{equation}\n",
    "\\min -4x_1-2x_2\\\\\n",
    "\\textrm{subject to}\n",
    "\\begin{cases}\n",
    "x_1+x_2+x_3&=5\\\\\n",
    "2x_1+\\frac{1}{2}x_2+x_4&=8\\\\\n",
    "\\vec x&\\ge \\vec 0\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Suppose we start with the basis index set $\\mathcal B=\\left\\{3,4\\right\\}$, for which we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [1 0;0 1]\n",
    "N = [1 1;2 0.5]\n",
    "b = [5;8]\n",
    "cB = [0;0]\n",
    "cN = [-4;-2]\n",
    "xB = inv(B)*b\n",
    "λ = inv(transpose(B))*cB\n",
    "sN = cN - transpose(N)*λ\n",
    "@show xB λ sN;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec x_\\mathbf B =\n",
    "\\begin{pmatrix}\n",
    "x_3\\\\\n",
    "x_4\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "5\\\\\n",
    "8\n",
    "\\end{pmatrix}\n",
    "\\,\\qquad\\vec\\lambda = \n",
    "\\begin{pmatrix}\n",
    "0\\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "\\,\\qquad\\vec s_\\mathbf N =\n",
    "\\begin{pmatrix}\n",
    "s_1\\\\\n",
    "s_2\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "-4\\\\\n",
    "-2\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "and an objective value of $\\vec{c}^\\mathsf{T}\\vec x=0$. Since both elements of $\\vec s_\\mathbf N$ are negative, we could choose either 1 or 2 to be the entering variable. Suppose we choose $q=1$. We obtain\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec d = \\begin{pmatrix}\n",
    "1\\\\\n",
    "2\n",
    "\\end{pmatrix}\\,,\n",
    "\\end{equation}\n",
    "\n",
    "so we cannot (yet) conclude that the problem is unbounded. By performing the ratio calculation, we find that $p=2$ (corresponding to index 4) and $x_1^+=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 1\n",
    "Aq = [1;2]\n",
    "d = inv(B)*Aq\n",
    "ratio = xB./d\n",
    "xq = minimum(ratio)\n",
    "xB -= d * xq\n",
    "@show d ratio xq xB;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the basic and nonbasic index sets to $\\mathcal B=\\left\\{3,1\\right\\}$ and  $\\mathcal N=\\left\\{4,2\\right\\}$, and move to the next iteration.\n",
    "\n",
    "At the second iteration, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [1 1;0 2]\n",
    "N = [0 1;1 0.5]\n",
    "cB = [0;-4]\n",
    "cN = [0;-2]\n",
    "xB = inv(B)*b\n",
    "λ = inv(transpose(B))*cB\n",
    "sN = cN - transpose(N)*λ\n",
    "@show xB λ sN;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec x_\\mathbf B =\n",
    "\\begin{pmatrix}\n",
    "x_3\\\\\n",
    "x_1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "1\\\\\n",
    "4\n",
    "\\end{pmatrix}\n",
    "\\,\\qquad\\vec\\lambda = \n",
    "\\begin{pmatrix}\n",
    "0\\\\\n",
    "-2\n",
    "\\end{pmatrix}\n",
    "\\,\\qquad\\vec s_\\mathbf N =\n",
    "\\begin{pmatrix}\n",
    "s_4\\\\\n",
    "s_2\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "2\\\\\n",
    "-1\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "with an objective value of -16. We see that $\\vec s_\\mathbf N$ has one negative component, corresponding to the index $q=2$, se we select this index to enter the basis. We obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 2\n",
    "Aq = [1;0.5]\n",
    "d = inv(B)*Aq\n",
    "ratio = xB./d\n",
    "xq = minimum(ratio)\n",
    "xB -= d * xq\n",
    "@show d ratio xq xB;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec d = \\begin{pmatrix}\n",
    "\\frac{3}{4}\\\\\n",
    "\\frac{1}{4}\n",
    "\\end{pmatrix}\\,,\n",
    "\\end{equation}\n",
    "\n",
    "so again we do not detect unboundedness. Continuing, we find that the minimum value of $x_2^+$ is $\\frac{4}{3}$, and that $p=1$, which indicates that index 3 will leave the basic index set $\\mathcal B$. We update the index sets to $\\mathcal B=\\left\\{2,1\\right\\}$ and  $\\mathcal N=\\left\\{4,3\\right\\}$ and continue.\n",
    "\n",
    "At the start of the third iteration, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [1 1;0.5 2]\n",
    "N = [1 0;0 1]\n",
    "cB = [-2;-4]\n",
    "cN = [0;0]\n",
    "xB = inv(B)*b\n",
    "λ = inv(transpose(B))*cB\n",
    "sN = cN - transpose(N)*λ\n",
    "@show xB λ sN;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\vec x_\\mathbf B =\n",
    "\\begin{pmatrix}\n",
    "x_2\\\\\n",
    "x_1\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "\\frac{4}{3}\\\\\n",
    "\\frac{11}{3}\n",
    "\\end{pmatrix}\n",
    "\\,\\qquad\\vec\\lambda = \n",
    "\\begin{pmatrix}\n",
    "-\\frac{4}{3}\\\\\n",
    "-\\frac{4}{3}\n",
    "\\end{pmatrix}\n",
    "\\,\\qquad\\vec s_\\mathbf N =\n",
    "\\begin{pmatrix}\n",
    "s_4\\\\\n",
    "s_3\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\frac{4}{3}\\\\\n",
    "\\frac{4}{3}\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "with an objective value of $-\\frac{52}{3}$. We see that $\\vec s_\\mathbf N\\ge\\vec 0$, so the optimality test is satisfied, and we terminate.\n",
    "\n",
    "We need to flesh out this procedure with specifics of three important aspects of the implementation:\n",
    "\n",
    "- Linear algebra issues—maintaining an LU factorization of $\\mathbf B$ that can be used to solve for $\\vec \\lambda$ and $\\vec d$.\n",
    "- Selection of the entering index $q$ from among the negative components of $\\vec s_\\mathbf N$. (In general, there are many such components.)\n",
    "- Handling of degenerate bases and degenerate steps, in which it is not possible to choose a positive value of $x_q$ without violating feasibility.\n",
    "\n",
    "Proper handling of these issues is crucial to the efficiency of a simplex implementation. We will use a software package handling these details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JuMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#pkg\"add JuMP GLPK\"\n",
    "\n",
    "using JuMP\n",
    "using GLPK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(with_optimizer(GLPK.Optimizer))\n",
    "@variable(model, 0 <= x1)\n",
    "@variable(model, 0 <= x2)\n",
    "@objective(model, Min, -4*x1 -2*x2)\n",
    "@constraint(model, con1, x1 + x2 <= 5)\n",
    "@constraint(model, con2, 2*x1 + 0.5*x2 <= 8)\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination_status(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primal_status(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_value(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LaTeXStrings\n",
    "\n",
    "x = -1:5\n",
    "plot(x, 5 .- x, linestyle=:dash, label=L\"x_1+x_2=5\")\n",
    "plot!(x, (8 .- 2 .* x) ./ 0.5, linestyle=:dash, label=L\"2x_1+0.5x_2=8\")\n",
    "plot!([0,4,11/3,0,0],[0,0,4/3,5,0], linewidth=2, label=\"constraints\")\n",
    "plot!(x, -4 .* x ./ 2, label=L\"f\\left(x_1,x_2\\right)=-4x_1-2x_2=0\")\n",
    "plot!(x, (-16 .+ 4 .* x) ./ -2, label=L\"f\\left(x_1,x_2\\right)=-4x_1-2x_2=-16\")\n",
    "plot!(x, (-52/3 .+ 4 .* x) ./ -2, label=L\"f\\left(x_1,x_2\\right)=-4x_1-2x_2=-52/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where does the Simplex Method fit?\n",
    "\n",
    "In linear programming, as in all optimization problems in which inequality constraints are present, the fundamental task of the algorithm is to determine which of these constraints are active at the solution and which are inactive. The simplex method belongs to a general class of algorithms for constrained optimization known as _active set methods_, which explicitly maintain estimates of the active and inactive index sets that are updated at each step of the algorithm. (At each iteration, the basis $\\mathcal B$ is our current estimate of the inactive set, that is, the set of indices $i$ for which we suspect that $x_i > 0$ at the\n",
    "solution of the linear program.) Like most active set methods, the simplex method makesonly modest changes to these index sets at each step; a single index is exchanged between $\\mathcal B$ into $\\mathcal N$.\n",
    "\n",
    "One undesirable feature of the simplex method attracted attention from its earliest days. Though highly efficient on almost all practical problems (the method generally requires at most $2m$ to $3m$ iterations, where $m$ is the row dimension of the constraint matrix, there are pathological problems on which the algorithm performs very poorly. The complexity of the simplex method is _exponential_, roughly speaking, its running time may be an exponential function of the dimension of\n",
    "the problem. For many years, theoreticians searched for a linear programming algorithm that has polynomial complexity, that is, an algorithm in which the running time is bounded by a polynomial function of the amount of storage required to define the problem.\n",
    "\n",
    "In the mid-1980s, Karmarkar described a polynomial algorithm that approaches the solution through the interior of the feasible polytope rather than working its way around the boundary as the simplex method does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interior Point Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
